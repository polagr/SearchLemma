{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\po1aa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\po1aa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk as nltk\n",
    "import numpy as np\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('searches.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "regexp = RegexpTokenizer('\\w+')\n",
    "df['text_tokens']=df['data'].apply(regexp.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>data</th>\n",
       "      <th>text_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>633462920851750912</td>\n",
       "      <td>U</td>\n",
       "      <td>[U]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>633463037382098944</td>\n",
       "      <td>U</td>\n",
       "      <td>[U]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>633463451380875264</td>\n",
       "      <td>office</td>\n",
       "      <td>[office]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>633463501641220096</td>\n",
       "      <td>Level</td>\n",
       "      <td>[Level]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>633463821058441216</td>\n",
       "      <td>office</td>\n",
       "      <td>[office]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7976</th>\n",
       "      <td>745006094333509632</td>\n",
       "      <td>Basic English</td>\n",
       "      <td>[Basic, English]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7977</th>\n",
       "      <td>745013032798650368</td>\n",
       "      <td>Basic English</td>\n",
       "      <td>[Basic, English]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7978</th>\n",
       "      <td>745023865217875968</td>\n",
       "      <td>Basic English</td>\n",
       "      <td>[Basic, English]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7979</th>\n",
       "      <td>745029321717972992</td>\n",
       "      <td>Basic English</td>\n",
       "      <td>[Basic, English]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7980</th>\n",
       "      <td>745049350941442048</td>\n",
       "      <td>Basic English</td>\n",
       "      <td>[Basic, English]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7981 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id           data       text_tokens\n",
       "0     633462920851750912              U               [U]\n",
       "1     633463037382098944              U               [U]\n",
       "2     633463451380875264         office          [office]\n",
       "3     633463501641220096          Level           [Level]\n",
       "4     633463821058441216         office          [office]\n",
       "...                  ...            ...               ...\n",
       "7976  745006094333509632  Basic English  [Basic, English]\n",
       "7977  745013032798650368  Basic English  [Basic, English]\n",
       "7978  745023865217875968  Basic English  [Basic, English]\n",
       "7979  745029321717972992  Basic English  [Basic, English]\n",
       "7980  745049350941442048  Basic English  [Basic, English]\n",
       "\n",
       "[7981 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['office',\n",
       " 'Level',\n",
       " 'office',\n",
       " 'asdfghjk',\n",
       " 'asdfghjk',\n",
       " 'Rule',\n",
       " 'Rule',\n",
       " 'French',\n",
       " 'French',\n",
       " 'Français',\n",
       " 'French',\n",
       " 'French',\n",
       " 'test123',\n",
       " 'test123',\n",
       " 'testing',\n",
       " 'class',\n",
       " 'ravinder',\n",
       " 'testing',\n",
       " 'class',\n",
       " 'ravinder',\n",
       " 'testing',\n",
       " 'class',\n",
       " 'ravinder',\n",
       " 'testing',\n",
       " 'class',\n",
       " 'ravinder',\n",
       " 'Testing',\n",
       " 'Class',\n",
       " 'Ravinder',\n",
       " 'Testing',\n",
       " 'Class',\n",
       " 'Ravinder',\n",
       " 'Testing',\n",
       " 'Class',\n",
       " 'Ravinder',\n",
       " 'Testing',\n",
       " 'Testing',\n",
       " 'Testing',\n",
       " 'Test',\n",
       " 'Test',\n",
       " 'Test',\n",
       " 'Test',\n",
       " 'Test',\n",
       " 'Testing',\n",
       " 'aaa',\n",
       " 'Test',\n",
       " 'aaa',\n",
       " 'Test',\n",
       " 'AAA',\n",
       " 'Cloned',\n",
       " 'class',\n",
       " 'Cloned',\n",
       " 'class',\n",
       " 'test',\n",
       " 'test',\n",
       " 'test',\n",
       " 'test',\n",
       " 'test',\n",
       " 'test',\n",
       " 'asdfghjkl',\n",
       " 'Graphic',\n",
       " 'design',\n",
       " 'Graphic',\n",
       " 'design',\n",
       " 'fashion',\n",
       " 'design',\n",
       " 'randa',\n",
       " 'mansour',\n",
       " 'parts',\n",
       " 'speech',\n",
       " 'parts',\n",
       " 'speech',\n",
       " 'french',\n",
       " 'french',\n",
       " 'Français',\n",
       " 'french',\n",
       " 'chin',\n",
       " 'chin',\n",
       " 'chin',\n",
       " 'Chinese',\n",
       " 'Fran',\n",
       " 'Business',\n",
       " 'Francais',\n",
       " 'Chinese',\n",
       " 'quo',\n",
       " 'Arabic',\n",
       " 'Chinese',\n",
       " 'Arabic',\n",
       " 'Chinese',\n",
       " 'Chinese',\n",
       " 'franca',\n",
       " 'quotidien',\n",
       " 'Yolla',\n",
       " 'Biology',\n",
       " 'Biology',\n",
       " 'Chin',\n",
       " 'francais',\n",
       " 'francais',\n",
       " 'fran',\n",
       " 'Français',\n",
       " 'fran',\n",
       " 'dira',\n",
       " 'Busin',\n",
       " 'fran',\n",
       " 'Yolla',\n",
       " 'Yolla',\n",
       " 'Land',\n",
       " 'grade',\n",
       " 'Office',\n",
       " 'Office',\n",
       " 'Office',\n",
       " 'Chin',\n",
       " 'Improve',\n",
       " 'parts',\n",
       " 'speech',\n",
       " 'randa',\n",
       " 'mansour',\n",
       " 'introduction',\n",
       " 'piano',\n",
       " 'introduction',\n",
       " 'piano',\n",
       " 'introduction',\n",
       " 'piano',\n",
       " '2nd',\n",
       " 'open',\n",
       " 'class',\n",
       " '2nd',\n",
       " 'opne',\n",
       " 'class',\n",
       " 'introduction',\n",
       " 'introduction',\n",
       " 'introduction',\n",
       " 'introduction',\n",
       " 'introduction',\n",
       " 'introduction',\n",
       " 'piano',\n",
       " 'Science',\n",
       " 'Experiment',\n",
       " 'Business',\n",
       " 'Studies',\n",
       " 'Cambridge',\n",
       " '0450',\n",
       " 'Business',\n",
       " 'Studies',\n",
       " 'Cambridge',\n",
       " '0450',\n",
       " 'WORD',\n",
       " '2019',\n",
       " 'LEVEL1',\n",
       " 'WORD',\n",
       " '2019',\n",
       " 'LEVEL1',\n",
       " 'Economics',\n",
       " 'Level',\n",
       " 'Economics',\n",
       " 'Level',\n",
       " 'sciences',\n",
       " 'fourth',\n",
       " 'grade',\n",
       " 'primary',\n",
       " 'stage',\n",
       " 'sciences',\n",
       " 'fourth',\n",
       " 'grade',\n",
       " 'primary',\n",
       " 'stage',\n",
       " 'Economics',\n",
       " 'Intermediate',\n",
       " 'Level',\n",
       " 'Economics',\n",
       " 'Intermediate',\n",
       " 'Level',\n",
       " 'Economics',\n",
       " 'Intermediate',\n",
       " 'Level',\n",
       " 'Economics',\n",
       " 'Intermediate',\n",
       " 'Level',\n",
       " 'Intermediate',\n",
       " 'Level',\n",
       " 'Economics',\n",
       " 'Intermediate',\n",
       " 'Level',\n",
       " 'Economics',\n",
       " 'Level',\n",
       " 'Economics',\n",
       " 'Level',\n",
       " 'Economics',\n",
       " 'Level',\n",
       " 'Business',\n",
       " 'Studies',\n",
       " 'IGCSE',\n",
       " 'Microsoft',\n",
       " 'Office',\n",
       " 'School',\n",
       " 'Microsoft',\n",
       " 'Office',\n",
       " 'School',\n",
       " 'WORD',\n",
       " '2019',\n",
       " 'LEVEL1',\n",
       " 'Economics',\n",
       " 'Level',\n",
       " 'sciences',\n",
       " 'fourth',\n",
       " 'grade',\n",
       " 'primary',\n",
       " 'stage',\n",
       " 'Economics',\n",
       " 'Intermediate',\n",
       " 'Level',\n",
       " 'parts',\n",
       " 'speech',\n",
       " 'English',\n",
       " 'Analytics',\n",
       " 'analytics',\n",
       " 'analytics',\n",
       " 'zeina',\n",
       " 'zeina',\n",
       " 'zeina',\n",
       " 'therapy',\n",
       " 'mind',\n",
       " 'Economics',\n",
       " 'Economics',\n",
       " 'Chemistry',\n",
       " 'Chemistry',\n",
       " 'Biology',\n",
       " 'Math',\n",
       " 'Pharmacy',\n",
       " 'chin',\n",
       " 'chin',\n",
       " 'chin',\n",
       " 'mohamad',\n",
       " 'yamout',\n",
       " 'mohamad',\n",
       " 'yamout',\n",
       " 'mohammad',\n",
       " 'mohamad',\n",
       " 'Cynthia',\n",
       " 'Chemistry',\n",
       " 'programming',\n",
       " 'python',\n",
       " 'Learn',\n",
       " 'Chinesse',\n",
       " 'beginners',\n",
       " 'Learn',\n",
       " 'Chinesse',\n",
       " 'beginners',\n",
       " 'Biology',\n",
       " 'Grade',\n",
       " 'Biology',\n",
       " 'Grade',\n",
       " 'Biology',\n",
       " 'Grade',\n",
       " 'Biologie',\n",
       " 'Biologie',\n",
       " 'Angela',\n",
       " 'Saad',\n",
       " 'Physics',\n",
       " 'Live',\n",
       " 'Sessions',\n",
       " 'Angela',\n",
       " 'Saad',\n",
       " 'Physics',\n",
       " 'Live',\n",
       " 'Sessions',\n",
       " 'Business',\n",
       " 'Studies',\n",
       " 'Cambridge',\n",
       " '0450',\n",
       " 'Business',\n",
       " 'Studies',\n",
       " 'Cambridge',\n",
       " '0450',\n",
       " 'Chemistry',\n",
       " 'Class',\n",
       " 'Chemistry',\n",
       " 'Class',\n",
       " 'WORD',\n",
       " '2019',\n",
       " 'LEVEL1',\n",
       " 'WORD',\n",
       " '2019',\n",
       " 'LEVEL1',\n",
       " 'Exploring',\n",
       " 'FREE',\n",
       " 'online',\n",
       " 'resources',\n",
       " 'aid',\n",
       " 'virtual',\n",
       " 'teaching',\n",
       " 'learning',\n",
       " 'Exploring',\n",
       " 'FREE',\n",
       " 'online',\n",
       " 'resources',\n",
       " 'aid',\n",
       " 'virtual',\n",
       " 'teaching',\n",
       " 'learning',\n",
       " 'Let',\n",
       " 'mind',\n",
       " 'work',\n",
       " 'Let',\n",
       " 'mind',\n",
       " 'work',\n",
       " 'Tips',\n",
       " 'Improve',\n",
       " 'teaching',\n",
       " 'Tips',\n",
       " 'Improve',\n",
       " 'teaching',\n",
       " 'Learn',\n",
       " 'Chinesse',\n",
       " 'beginners',\n",
       " 'Learn',\n",
       " 'Chinesse',\n",
       " 'beginners',\n",
       " 'Nicole',\n",
       " 'Live',\n",
       " 'Session',\n",
       " 'Nicole',\n",
       " 'Live',\n",
       " 'Session',\n",
       " 'Chemistry',\n",
       " 'Class',\n",
       " 'Chemistry',\n",
       " 'Class',\n",
       " 'The',\n",
       " 'book',\n",
       " 'club',\n",
       " 'The',\n",
       " 'book',\n",
       " 'club',\n",
       " 'Economics',\n",
       " 'Basics',\n",
       " 'Economics',\n",
       " 'Basics',\n",
       " 'chinese',\n",
       " 'chinese',\n",
       " 'chinese',\n",
       " 'chinese',\n",
       " 'chinese',\n",
       " 'math',\n",
       " 'francais',\n",
       " 'jal',\n",
       " 'jal',\n",
       " 'jal',\n",
       " 'physical',\n",
       " 'get',\n",
       " 'sports',\n",
       " 'sports',\n",
       " 'sports',\n",
       " 'Tip',\n",
       " 'Tip',\n",
       " 'ielts',\n",
       " 'ielts',\n",
       " 'english',\n",
       " 'english',\n",
       " 'science',\n",
       " 'science',\n",
       " 'science',\n",
       " 'diet',\n",
       " 'diet',\n",
       " 'diet',\n",
       " 'diet',\n",
       " 'yoga',\n",
       " 'yoga',\n",
       " 'yoga',\n",
       " 'meditation',\n",
       " 'nutrition',\n",
       " 'nutrition',\n",
       " 'nutrition',\n",
       " 'BIOLOGY',\n",
       " 'nathalie',\n",
       " 'nathalie',\n",
       " 'nathalie',\n",
       " 'nathalie',\n",
       " 'french',\n",
       " 'french',\n",
       " 'language',\n",
       " 'arabic',\n",
       " 'arabic',\n",
       " 'chinese',\n",
       " 'gehad',\n",
       " 'gehad',\n",
       " 'gihad',\n",
       " 'green',\n",
       " 'green',\n",
       " 'green',\n",
       " 'Ahmed',\n",
       " 'rashad',\n",
       " 'Ahmed',\n",
       " 'rashad',\n",
       " 'meditation',\n",
       " 'https',\n",
       " 'app',\n",
       " 'oktopi',\n",
       " 'invitation',\n",
       " 'enroll',\n",
       " '1b495db9',\n",
       " 'c03f',\n",
       " '425f',\n",
       " 'bf08',\n",
       " 'b873533205c9',\n",
       " 'Ahmed',\n",
       " 'rashad',\n",
       " 'Ahmed',\n",
       " 'rashad',\n",
       " 'art',\n",
       " 'art',\n",
       " 'art',\n",
       " 'ahmed',\n",
       " 'rashad',\n",
       " 'ahmed',\n",
       " 'rashad',\n",
       " 'AHMED',\n",
       " 'RASHAD',\n",
       " 'AHMED',\n",
       " 'RASHAD',\n",
       " 'AHMED',\n",
       " 'RASHAD',\n",
       " 'rashad',\n",
       " 'rashad',\n",
       " 'ahmed',\n",
       " 'rashad',\n",
       " 'ahmed',\n",
       " 'rashad',\n",
       " 'ahmed',\n",
       " 'rashad',\n",
       " 'essential',\n",
       " 'digital',\n",
       " 'music',\n",
       " 'italian',\n",
       " 'italian',\n",
       " 'italiano',\n",
       " 'italian',\n",
       " 'igcse',\n",
       " 'igcse',\n",
       " 'Math',\n",
       " 'Math',\n",
       " 'igcse',\n",
       " 'Math',\n",
       " 'igcse',\n",
       " 'Class',\n",
       " 'demo',\n",
       " 'Class',\n",
       " 'demo',\n",
       " 'Class',\n",
       " 'demo',\n",
       " 'Second',\n",
       " 'Second',\n",
       " 'Second',\n",
       " 'Second',\n",
       " 'Emad',\n",
       " 'Elaswany',\n",
       " 'Emad',\n",
       " 'Elaswany',\n",
       " 'saber',\n",
       " 'emam',\n",
       " 'saber',\n",
       " 'emam',\n",
       " 'saber',\n",
       " 'emam',\n",
       " 'saber',\n",
       " 'saber',\n",
       " 'emam',\n",
       " 'Transformation',\n",
       " 'Zeina',\n",
       " 'Zaina',\n",
       " 'Zena',\n",
       " 'Level',\n",
       " 'Level',\n",
       " 'Level1',\n",
       " 'Manifest',\n",
       " 'life',\n",
       " 'want',\n",
       " 'Manifest',\n",
       " 'life',\n",
       " 'want',\n",
       " 'Learn',\n",
       " 'English',\n",
       " 'Elza',\n",
       " 'Two',\n",
       " 'Live',\n",
       " 'Sessions',\n",
       " 'Learn',\n",
       " 'English',\n",
       " 'Elza',\n",
       " 'Two',\n",
       " 'Live',\n",
       " 'Sessions',\n",
       " 'Learn',\n",
       " 'English',\n",
       " 'Elza',\n",
       " 'Two',\n",
       " 'Live',\n",
       " 'Sessions',\n",
       " 'Learn',\n",
       " 'Chinesse',\n",
       " 'beginners',\n",
       " 'Learn',\n",
       " 'Chinesse',\n",
       " 'beginners',\n",
       " 'Dream',\n",
       " 'IELTS',\n",
       " 'Band',\n",
       " 'Score',\n",
       " 'LIVE',\n",
       " 'SESSIONS',\n",
       " 'Dream',\n",
       " 'IELTS',\n",
       " 'Band',\n",
       " 'Score',\n",
       " 'LIVE',\n",
       " 'SESSIONS',\n",
       " 'Geometry',\n",
       " 'Algebra',\n",
       " 'Grades',\n",
       " 'Geometry',\n",
       " 'Algebra',\n",
       " 'Grades',\n",
       " 'Nicole',\n",
       " 'Live',\n",
       " 'Session',\n",
       " 'Geometry',\n",
       " 'Algebra',\n",
       " 'Grades',\n",
       " 'Geometry',\n",
       " 'Algebra',\n",
       " 'Grades',\n",
       " 'Nicole',\n",
       " 'Live',\n",
       " 'Session',\n",
       " 'Nicole',\n",
       " 'Live',\n",
       " 'Session',\n",
       " 'Nicole',\n",
       " 'Live',\n",
       " 'Session',\n",
       " 'Nicole',\n",
       " 'Live',\n",
       " 'Session',\n",
       " 'Nicole',\n",
       " 'Live',\n",
       " 'Session',\n",
       " 'Learn',\n",
       " 'Chinesse',\n",
       " 'beginners',\n",
       " 'Second',\n",
       " 'Secondary',\n",
       " 'Third',\n",
       " 'Secondary',\n",
       " 'yolla',\n",
       " 'yolla',\n",
       " 'Ahmed',\n",
       " 'rashad',\n",
       " 'Ahmed',\n",
       " 'rashad',\n",
       " 'Ahmed',\n",
       " 'rashad',\n",
       " 'Third',\n",
       " 'secondary',\n",
       " '2022',\n",
       " 'Third',\n",
       " 'secondary',\n",
       " '2022',\n",
       " 'Third',\n",
       " 'secondary',\n",
       " '2022',\n",
       " 'chinese',\n",
       " 'chinese',\n",
       " 'chinese',\n",
       " 'ahmed',\n",
       " 'ahmed',\n",
       " 'ahmed',\n",
       " 'rashad',\n",
       " 'nabih',\n",
       " 'rashad',\n",
       " 'rashad',\n",
       " 'ahmed',\n",
       " 'rashad',\n",
       " 'ahmed',\n",
       " 'rashad',\n",
       " 'ahmed',\n",
       " 'rashad',\n",
       " 'ahmed',\n",
       " 'rashad',\n",
       " 'dashboard',\n",
       " 'dashboard',\n",
       " 'rash',\n",
       " 'rash',\n",
       " 'tamara',\n",
       " 'doumit',\n",
       " 'tamara',\n",
       " 'doumit',\n",
       " 'design',\n",
       " 'iii',\n",
       " 'yyy',\n",
       " 'yyy',\n",
       " 'yyy',\n",
       " 'yyy',\n",
       " 'weight',\n",
       " 'lose',\n",
       " 'lose',\n",
       " 'weight',\n",
       " 'donia',\n",
       " 'abi',\n",
       " 'nassif',\n",
       " 'donia',\n",
       " 'abi',\n",
       " 'nassif',\n",
       " 'donia',\n",
       " 'donia',\n",
       " 'nassif',\n",
       " 'world',\n",
       " 'nutrition',\n",
       " 'diet',\n",
       " 'diet',\n",
       " 'weight',\n",
       " 'Oral',\n",
       " 'Pathology',\n",
       " 'Oral',\n",
       " 'Pathology',\n",
       " 'Oral',\n",
       " 'free',\n",
       " 'math',\n",
       " 'classes',\n",
       " 'free',\n",
       " 'math',\n",
       " 'classes',\n",
       " 'iqraa',\n",
       " 'iqraa',\n",
       " 'Arabic',\n",
       " 'Young',\n",
       " 'Learners',\n",
       " 'years',\n",
       " 'old',\n",
       " 'Learn',\n",
       " 'Chinesse',\n",
       " 'beginners',\n",
       " 'Learn',\n",
       " 'Chinesse',\n",
       " 'beginners',\n",
       " 'Learn',\n",
       " 'Chinesse',\n",
       " 'beginners',\n",
       " 'Learn',\n",
       " 'Chinesse',\n",
       " 'beginners',\n",
       " 'Learn',\n",
       " 'Chinesse',\n",
       " 'beginners',\n",
       " 'FIVE',\n",
       " 'Reasons',\n",
       " 'Why',\n",
       " 'You',\n",
       " 'Just',\n",
       " 'Can',\n",
       " 'Lose',\n",
       " 'Weight',\n",
       " 'FIVE',\n",
       " 'Reasons',\n",
       " 'Why',\n",
       " 'You',\n",
       " 'Just',\n",
       " 'Can',\n",
       " 'Lose',\n",
       " 'Weight',\n",
       " 'Unraveled',\n",
       " 'Nutrition',\n",
       " 'Facts',\n",
       " 'Unraveled',\n",
       " 'Nutrition',\n",
       " 'Facts',\n",
       " 'FIVE',\n",
       " 'Reasons',\n",
       " 'Why',\n",
       " 'You',\n",
       " 'Just',\n",
       " 'Can',\n",
       " 'Lose',\n",
       " 'Weight',\n",
       " 'FIVE',\n",
       " 'Reasons',\n",
       " 'Why',\n",
       " 'You',\n",
       " 'Just',\n",
       " 'Can',\n",
       " 'Lose',\n",
       " 'Weight',\n",
       " 'Learn',\n",
       " 'Chinesse',\n",
       " 'beginners',\n",
       " 'Learn',\n",
       " 'Chinesse',\n",
       " 'beginners',\n",
       " 'Arabic',\n",
       " 'Young',\n",
       " 'Learners',\n",
       " 'years',\n",
       " 'old',\n",
       " 'Manifest',\n",
       " 'life',\n",
       " 'want',\n",
       " 'Live',\n",
       " 'Session',\n",
       " 'Manifest',\n",
       " 'life',\n",
       " 'want',\n",
       " 'Live',\n",
       " 'Session',\n",
       " 'Learn',\n",
       " 'Green',\n",
       " 'Cities',\n",
       " 'Design',\n",
       " 'LIVE',\n",
       " 'SESSION',\n",
       " 'INCLUDED',\n",
       " 'Learn',\n",
       " 'Green',\n",
       " 'Cities',\n",
       " 'Design',\n",
       " 'LIVE',\n",
       " 'SESSION',\n",
       " 'INCLUDED',\n",
       " 'Basics',\n",
       " 'Fashion',\n",
       " 'Design',\n",
       " 'Basics',\n",
       " 'Fashion',\n",
       " 'Design',\n",
       " 'Music',\n",
       " 'Theory',\n",
       " 'Computer',\n",
       " 'Musicians',\n",
       " 'Session',\n",
       " 'min',\n",
       " 'Music',\n",
       " 'Theory',\n",
       " 'Computer',\n",
       " 'Musicians',\n",
       " 'Session',\n",
       " 'min',\n",
       " 'Sound',\n",
       " 'Design',\n",
       " 'Synthesis',\n",
       " 'Private',\n",
       " 'Session',\n",
       " 'min',\n",
       " 'Sound',\n",
       " 'Design',\n",
       " 'Synthesis',\n",
       " 'Private',\n",
       " 'Session',\n",
       " 'min',\n",
       " 'Learn',\n",
       " 'Chemistry',\n",
       " 'Bruna',\n",
       " 'Two',\n",
       " 'Live',\n",
       " 'Sessions',\n",
       " 'Learn',\n",
       " 'Chemistry',\n",
       " 'Bruna',\n",
       " 'Two',\n",
       " 'Live',\n",
       " 'Sessions',\n",
       " 'Geometry',\n",
       " 'Algebra',\n",
       " 'Grades',\n",
       " 'Geometry',\n",
       " 'Algebra',\n",
       " 'Grades',\n",
       " 'Music',\n",
       " 'Production',\n",
       " 'Sound',\n",
       " 'Design',\n",
       " 'Master',\n",
       " 'Course',\n",
       " 'min',\n",
       " 'Music',\n",
       " 'Production',\n",
       " 'Learn',\n",
       " 'Math',\n",
       " 'Nicole',\n",
       " 'Two',\n",
       " 'Live',\n",
       " 'Sessions',\n",
       " 'Learn',\n",
       " 'Math',\n",
       " 'Nicole',\n",
       " 'Two',\n",
       " 'Live',\n",
       " 'Sessions',\n",
       " 'Nicole',\n",
       " 'Live',\n",
       " 'Session',\n",
       " 'Nicole',\n",
       " 'Live',\n",
       " 'Session',\n",
       " 'Learn',\n",
       " 'English',\n",
       " 'Elza',\n",
       " 'Two',\n",
       " 'Live',\n",
       " 'Sessions',\n",
       " 'Learn',\n",
       " 'English',\n",
       " 'Elza',\n",
       " 'Two',\n",
       " 'Live',\n",
       " 'Sessions',\n",
       " 'Dream',\n",
       " 'IELTS',\n",
       " 'Band',\n",
       " 'Score',\n",
       " 'LIVE',\n",
       " 'SESSIONS',\n",
       " 'Dream',\n",
       " 'IELTS',\n",
       " 'Band',\n",
       " 'Score',\n",
       " 'LIVE',\n",
       " 'SESSIONS',\n",
       " 'Sun',\n",
       " 'Salutation',\n",
       " 'Economics',\n",
       " 'Intermediate',\n",
       " 'Level',\n",
       " 'Economics',\n",
       " 'Intermediate',\n",
       " 'Level',\n",
       " 'Economics',\n",
       " 'Senior',\n",
       " 'Level',\n",
       " 'Economics',\n",
       " 'Senior',\n",
       " 'Level',\n",
       " 'Essential',\n",
       " 'Mixing',\n",
       " 'Mastering',\n",
       " 'Private',\n",
       " 'Session',\n",
       " 'min',\n",
       " 'Maths',\n",
       " '101',\n",
       " 'Maths',\n",
       " '101',\n",
       " 'yoga',\n",
       " 'sun',\n",
       " 'sun',\n",
       " 'French',\n",
       " 'French',\n",
       " 'French',\n",
       " 'Bright',\n",
       " 'Student',\n",
       " 'Learning',\n",
       " 'Center',\n",
       " 'Bright',\n",
       " 'Student',\n",
       " 'Bright',\n",
       " 'Student',\n",
       " 'Bright',\n",
       " 'Student',\n",
       " 'cbse',\n",
       " 'french',\n",
       " 'cbse',\n",
       " 'french',\n",
       " 'French',\n",
       " 'coding',\n",
       " 'coding',\n",
       " 'coding',\n",
       " 'coding',\n",
       " 'Apprendre',\n",
       " 'Apprendre',\n",
       " 'Apprendre',\n",
       " 'class',\n",
       " 'CBSE',\n",
       " 'FREbcg',\n",
       " 'class',\n",
       " 'class',\n",
       " 'cbse',\n",
       " 'chinese',\n",
       " 'chinese',\n",
       " 'rowaida',\n",
       " 'rowaida',\n",
       " 'rowaida',\n",
       " 'chaker',\n",
       " 'shaker',\n",
       " 'chaker',\n",
       " 'chaker',\n",
       " 'Biology',\n",
       " 'Biology',\n",
       " 'chinese',\n",
       " 'chinese',\n",
       " 'chinese',\n",
       " 'donia',\n",
       " 'abi',\n",
       " 'nassif',\n",
       " 'donia',\n",
       " 'abi',\n",
       " 'nassif',\n",
       " 'donia',\n",
       " 'nassif',\n",
       " 'chinese',\n",
       " 'chinese',\n",
       " 'cynthia',\n",
       " 'economics',\n",
       " 'economics',\n",
       " 'economics',\n",
       " 'economics',\n",
       " 'economics',\n",
       " 'economics',\n",
       " 'economics',\n",
       " 'economics',\n",
       " 'economics',\n",
       " 'economics',\n",
       " 'math',\n",
       " 'math',\n",
       " 'english',\n",
       " 'english',\n",
       " 'english',\n",
       " 'english',\n",
       " 'english',\n",
       " 'english',\n",
       " 'english',\n",
       " 'english',\n",
       " 'english',\n",
       " 'greek',\n",
       " 'greek',\n",
       " 'greek',\n",
       " 'elie',\n",
       " 'elie',\n",
       " 'eli',\n",
       " 'manifestation',\n",
       " 'yolla',\n",
       " 'elie',\n",
       " 'chinese',\n",
       " 'chinese',\n",
       " 'fadi',\n",
       " 'chinese',\n",
       " 'arab',\n",
       " 'mani',\n",
       " 'life',\n",
       " 'open',\n",
       " 'scheduled',\n",
       " 'schedul',\n",
       " 'sch',\n",
       " 'randa',\n",
       " 'frensh',\n",
       " 'frac',\n",
       " 'fran',\n",
       " 'dir',\n",
       " 'kora',\n",
       " 'Zein',\n",
       " 'dir',\n",
       " 'remote',\n",
       " 'sensing',\n",
       " 'French',\n",
       " 'French',\n",
       " 'French',\n",
       " 'skillz',\n",
       " 'skillz',\n",
       " 'fashion',\n",
       " 'fashion',\n",
       " 'Creative',\n",
       " 'Writing',\n",
       " 'Creative',\n",
       " 'Writing',\n",
       " 'skillz',\n",
       " 'skillz',\n",
       " 'mona',\n",
       " 'raouf',\n",
       " 'mona',\n",
       " 'raouf',\n",
       " 'french',\n",
       " 'French',\n",
       " 'Group',\n",
       " 'french',\n",
       " 'group',\n",
       " 'mohammed',\n",
       " 'abdulmoniem',\n",
       " 'mohamed',\n",
       " 'abdelmoniem',\n",
       " 'mohamed',\n",
       " 'abdelmoniem',\n",
       " 'free',\n",
       " 'class',\n",
       " 'Mrs',\n",
       " 'Sylvia',\n",
       " 'Sylvia',\n",
       " 'SAT',\n",
       " 'group',\n",
       " 'SAT',\n",
       " 'group',\n",
       " 'SAT',\n",
       " 'group',\n",
       " 'SAT',\n",
       " 'group',\n",
       " ...]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text_tokens'] = df['text_tokens'].apply(lambda x: [item for item in x if item not in stopwords])\n",
    "df['text_string'] = df['text_tokens'].apply(lambda x: ' '.join([item for item in x if len(item)>2]))\n",
    "all_words = ' '.join([word for word in df['text_string']])\n",
    "tokenized_words = nltk.tokenize.word_tokenize(all_words)\n",
    "tokenized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'English': 634, 'Basic': 419, 'Fashion': 392, 'Chinese': 389, 'rashad': 195, 'Ahmed': 140, 'ahmed': 135, 'math': 126, 'english': 124, 'Learn': 117, ...})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frqdist = FreqDist(tokenized_words)\n",
    "frqdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>data</th>\n",
       "      <th>text_tokens</th>\n",
       "      <th>text_string</th>\n",
       "      <th>text_string_fdist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>633462920851750912</td>\n",
       "      <td>U</td>\n",
       "      <td>[U]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>633463037382098944</td>\n",
       "      <td>U</td>\n",
       "      <td>[U]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>633463451380875264</td>\n",
       "      <td>office</td>\n",
       "      <td>[office]</td>\n",
       "      <td>office</td>\n",
       "      <td>office</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>633463501641220096</td>\n",
       "      <td>Level</td>\n",
       "      <td>[Level]</td>\n",
       "      <td>Level</td>\n",
       "      <td>Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>633463821058441216</td>\n",
       "      <td>office</td>\n",
       "      <td>[office]</td>\n",
       "      <td>office</td>\n",
       "      <td>office</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7976</th>\n",
       "      <td>745006094333509632</td>\n",
       "      <td>Basic English</td>\n",
       "      <td>[Basic, English]</td>\n",
       "      <td>Basic English</td>\n",
       "      <td>Basic English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7977</th>\n",
       "      <td>745013032798650368</td>\n",
       "      <td>Basic English</td>\n",
       "      <td>[Basic, English]</td>\n",
       "      <td>Basic English</td>\n",
       "      <td>Basic English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7978</th>\n",
       "      <td>745023865217875968</td>\n",
       "      <td>Basic English</td>\n",
       "      <td>[Basic, English]</td>\n",
       "      <td>Basic English</td>\n",
       "      <td>Basic English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7979</th>\n",
       "      <td>745029321717972992</td>\n",
       "      <td>Basic English</td>\n",
       "      <td>[Basic, English]</td>\n",
       "      <td>Basic English</td>\n",
       "      <td>Basic English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7980</th>\n",
       "      <td>745049350941442048</td>\n",
       "      <td>Basic English</td>\n",
       "      <td>[Basic, English]</td>\n",
       "      <td>Basic English</td>\n",
       "      <td>Basic English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7981 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id           data       text_tokens    text_string  \\\n",
       "0     633462920851750912              U               [U]                  \n",
       "1     633463037382098944              U               [U]                  \n",
       "2     633463451380875264         office          [office]         office   \n",
       "3     633463501641220096          Level           [Level]          Level   \n",
       "4     633463821058441216         office          [office]         office   \n",
       "...                  ...            ...               ...            ...   \n",
       "7976  745006094333509632  Basic English  [Basic, English]  Basic English   \n",
       "7977  745013032798650368  Basic English  [Basic, English]  Basic English   \n",
       "7978  745023865217875968  Basic English  [Basic, English]  Basic English   \n",
       "7979  745029321717972992  Basic English  [Basic, English]  Basic English   \n",
       "7980  745049350941442048  Basic English  [Basic, English]  Basic English   \n",
       "\n",
       "     text_string_fdist  \n",
       "0                       \n",
       "1                       \n",
       "2               office  \n",
       "3                Level  \n",
       "4               office  \n",
       "...                ...  \n",
       "7976     Basic English  \n",
       "7977     Basic English  \n",
       "7978     Basic English  \n",
       "7979     Basic English  \n",
       "7980     Basic English  \n",
       "\n",
       "[7981 rows x 5 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text_string_fdist'] = df['text_tokens'].apply(lambda x: ' '.join([item for item in x if frqdist[item] >= 1 ]))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\po1aa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\po1aa\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>data</th>\n",
       "      <th>text_tokens</th>\n",
       "      <th>text_string</th>\n",
       "      <th>text_string_fdist</th>\n",
       "      <th>text_string_lem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>633462920851750912</td>\n",
       "      <td>U</td>\n",
       "      <td>[U]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>633463037382098944</td>\n",
       "      <td>U</td>\n",
       "      <td>[U]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>633463451380875264</td>\n",
       "      <td>office</td>\n",
       "      <td>[office]</td>\n",
       "      <td>office</td>\n",
       "      <td>office</td>\n",
       "      <td>office</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>633463501641220096</td>\n",
       "      <td>Level</td>\n",
       "      <td>[Level]</td>\n",
       "      <td>Level</td>\n",
       "      <td>Level</td>\n",
       "      <td>Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>633463821058441216</td>\n",
       "      <td>office</td>\n",
       "      <td>[office]</td>\n",
       "      <td>office</td>\n",
       "      <td>office</td>\n",
       "      <td>office</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7976</th>\n",
       "      <td>745006094333509632</td>\n",
       "      <td>Basic English</td>\n",
       "      <td>[Basic, English]</td>\n",
       "      <td>Basic English</td>\n",
       "      <td>Basic English</td>\n",
       "      <td>Basic English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7977</th>\n",
       "      <td>745013032798650368</td>\n",
       "      <td>Basic English</td>\n",
       "      <td>[Basic, English]</td>\n",
       "      <td>Basic English</td>\n",
       "      <td>Basic English</td>\n",
       "      <td>Basic English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7978</th>\n",
       "      <td>745023865217875968</td>\n",
       "      <td>Basic English</td>\n",
       "      <td>[Basic, English]</td>\n",
       "      <td>Basic English</td>\n",
       "      <td>Basic English</td>\n",
       "      <td>Basic English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7979</th>\n",
       "      <td>745029321717972992</td>\n",
       "      <td>Basic English</td>\n",
       "      <td>[Basic, English]</td>\n",
       "      <td>Basic English</td>\n",
       "      <td>Basic English</td>\n",
       "      <td>Basic English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7980</th>\n",
       "      <td>745049350941442048</td>\n",
       "      <td>Basic English</td>\n",
       "      <td>[Basic, English]</td>\n",
       "      <td>Basic English</td>\n",
       "      <td>Basic English</td>\n",
       "      <td>Basic English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7981 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id           data       text_tokens    text_string  \\\n",
       "0     633462920851750912              U               [U]                  \n",
       "1     633463037382098944              U               [U]                  \n",
       "2     633463451380875264         office          [office]         office   \n",
       "3     633463501641220096          Level           [Level]          Level   \n",
       "4     633463821058441216         office          [office]         office   \n",
       "...                  ...            ...               ...            ...   \n",
       "7976  745006094333509632  Basic English  [Basic, English]  Basic English   \n",
       "7977  745013032798650368  Basic English  [Basic, English]  Basic English   \n",
       "7978  745023865217875968  Basic English  [Basic, English]  Basic English   \n",
       "7979  745029321717972992  Basic English  [Basic, English]  Basic English   \n",
       "7980  745049350941442048  Basic English  [Basic, English]  Basic English   \n",
       "\n",
       "     text_string_fdist text_string_lem  \n",
       "0                                       \n",
       "1                                       \n",
       "2               office          office  \n",
       "3                Level           Level  \n",
       "4               office          office  \n",
       "...                ...             ...  \n",
       "7976     Basic English   Basic English  \n",
       "7977     Basic English   Basic English  \n",
       "7978     Basic English   Basic English  \n",
       "7979     Basic English   Basic English  \n",
       "7980     Basic English   Basic English  \n",
       "\n",
       "[7981 rows x 6 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordnet_lem = WordNetLemmatizer()\n",
    "df['text_string_lem'] = df['text_string_fdist'].apply(wordnet_lem.lemmatize)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_equal']= (df['text_string_fdist']==df['text_string_lem'])\n",
    "df.is_equal.value_counts()\n",
    "df.to_csv('final.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
